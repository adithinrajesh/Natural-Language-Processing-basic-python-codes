{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d3f2a0-36e0-472d-828f-e6285f958f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b640dfd4-6e75-47fb-a526-e8f26858bc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing , enable non-subject matter experts to find answers to their questions . Natural Language Processing , analyze data from both structured and unstructured sources . Natural Language Processing , identify the root causes of your business problems . Natural Language Processing , discover your most profitable customers and understand the reasons behind it . Natural Language Processing , combines Artificial Intelligence AI and computational linguistics so that computers and humans can talk seamlessly .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"webtext.txt\",\"r\") as f:\n",
    "    text = f.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "329c531b-7afe-4b99-871c-6d0726ccec7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', ',', 'enable', 'non-subject', 'matter', 'experts', 'to', 'find', 'answers', 'to', 'their', 'questions', '.', 'Natural', 'Language', 'Processing', ',', 'analyze', 'data', 'from', 'both', 'structured', 'and', 'unstructured', 'sources', '.', 'Natural', 'Language', 'Processing', ',', 'identify', 'the', 'root', 'causes', 'of', 'your', 'business', 'problems', '.', 'Natural', 'Language', 'Processing', ',', 'discover', 'your', 'most', 'profitable', 'customers', 'and', 'understand', 'the', 'reasons', 'behind', 'it', '.', 'Natural', 'Language', 'Processing', ',', 'combines', 'Artificial', 'Intelligence', 'AI', 'and', 'computational', 'linguistics', 'so', 'that', 'computers', 'and', 'humans', 'can', 'talk', 'seamlessly', '.']\n"
     ]
    }
   ],
   "source": [
    "#tokenisation\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19fd8731-535c-4307-a634-063032eeb657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Processing', 'enable', 'non-subject', 'matter', 'experts', 'find', 'answers', 'questions', 'Natural', 'Language', 'Processing', 'analyze', 'data', 'structured', 'unstructured', 'sources', 'Natural', 'Language', 'Processing', 'identify', 'root', 'causes', 'business', 'problems', 'Natural', 'Language', 'Processing', 'discover', 'profitable', 'customers', 'understand', 'reasons', 'behind', 'Natural', 'Language', 'Processing', 'combines', 'Artificial', 'Intelligence', 'AI', 'computational', 'linguistics', 'computers', 'humans', 'talk', 'seamlessly']\n"
     ]
    }
   ],
   "source": [
    "#Stop word removal\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "fil_tokens = [word for word in tokens if (word not in stop_words and word not in string.punctuation)]\n",
    "print(fil_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c22bb143-4f91-41e2-be01-3304c3891559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding collocations\n",
    "def find_collo(fil_tokens, cv):\n",
    "    collo = set()\n",
    "    n = len(fil_tokens)\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        w1, w2 = fil_tokens[i], fil_tokens[i+1]\n",
    "        \n",
    "        ttest_res = ttest(w1, w2, fil_tokens, cv)\n",
    "        \n",
    "        if ttest_res:\n",
    "            collo.add(tuple(ttest_res))\n",
    "    \n",
    "    return collo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "036c6579-6364-4657-8cc4-eff19a5c0e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(w1, w2, fil_tokens, cv):\n",
    "    n = len(fil_tokens)\n",
    "    res = []\n",
    "    cw1 = fil_tokens.count(w1)\n",
    "    cw2 = fil_tokens.count(w2)\n",
    "    exp = ((cw1/n)*(cw2/n))\n",
    "\n",
    "    j = 0\n",
    "    for i in range(n-1):\n",
    "        if fil_tokens[i] == w1 or fil_tokens[i+1] == w2:\n",
    "            j+=1\n",
    "    pw12 = j\n",
    "    obs = pw12/n\n",
    "    t = ((obs-exp)/(obs/n)**0.5)\n",
    "\n",
    "    if t>cv:\n",
    "        res.append(w1)\n",
    "        res.append(w2)\n",
    "        res.append(t)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf29095f-ad14-4947-b473-32a1adca401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#critical value\n",
    "cv = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f97b826-e2cc-406b-a6c9-bc67af183a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocations =  Processing discover\n",
      "T statistics =  2.189483227968544\n",
      "\n",
      "Collocations =  Processing combines\n",
      "T statistics =  2.189483227968544\n",
      "\n",
      "Collocations =  Processing enable\n",
      "T statistics =  2.189483227968544\n",
      "\n",
      "Collocations =  Natural Language\n",
      "T statistics =  2.0031442298435618\n",
      "\n",
      "Collocations =  Processing analyze\n",
      "T statistics =  2.189483227968544\n",
      "\n",
      "Collocations =  Processing identify\n",
      "T statistics =  2.189483227968544\n",
      "\n",
      "Collocations =  Language Processing\n",
      "T statistics =  2.0031442298435618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uni_collo = find_collo(fil_tokens, cv)\n",
    "\n",
    "for col in uni_collo:\n",
    "    print(\"Collocations = \", col[0], col[1])\n",
    "    print(\"T statistics = \", col[2])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a3531-2cf5-41a4-a12e-948b973270a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
